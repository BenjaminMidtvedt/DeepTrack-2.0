{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds the module to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import glob    \n",
    "\n",
    "import deeptrack as dt\n",
    "\n",
    "PATH_TO_DATASET = \"./datasets/MitoGAN/\"\n",
    "\n",
    "TRAINING_PATH =  sorted(glob.glob(PATH_TO_DATASET + 'train/*'))\n",
    "VALIDATION_PATH =  sorted(glob.glob(PATH_TO_DATASET + 'validation/*'))\n",
    "\n",
    "number_of_training_files = len([file for file in TRAINING_PATH if \"membranes_\" in file])\n",
    "number_of_validation_files = len([file for file in VALIDATION_PATH if \"membranes_\" in file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_index_iterator = itertools.cycle(iter(range(number_of_training_files)))\n",
    "validation_index_iterator = itertools.cycle(iter(range(number_of_validation_files)))\n",
    "\n",
    "validation_path = PATH_TO_DATASET + 'validation/'\n",
    "training_path =PATH_TO_DATASET + 'train/'\n",
    "\n",
    "root = dt.DummyFeature(\n",
    "    base_path=lambda validation: validation_path if validation else training_path,\n",
    "    index=lambda validation: next(validation_index_iterator) if validation \\\n",
    "                             else next(training_index_iterator)\n",
    ")\n",
    "\n",
    "load_training_image = root + dt.LoadImage(\n",
    "    path = lambda index, base_path: base_path + 'raw_' + str(index) + '.png',\n",
    "    **root.properties\n",
    ")\n",
    "\n",
    "\n",
    "load_training_membranes = root + dt.LoadImage(\n",
    "    path = lambda index, base_path: base_path + 'membranes_' + str(index) + '.png',\n",
    "    **root.properties\n",
    ") \n",
    "\n",
    "load_training_mitochondria = root + dt.LoadImage(\n",
    "    path = lambda index, base_path: base_path + 'mitochondria_' + str(index) + '.png',\n",
    "    **root.properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a):\n",
    "    # normalize between 0 and 1\n",
    "    b = (a - np.min(a, axis=(0, 1),keepdims = True))/np.ptp(a, axis=(0, 1), keepdims = True)\n",
    "    # normalize between -1 and 1\n",
    "    b = 2.*b-1\n",
    "    \n",
    "    return b         \n",
    "\n",
    "normalization = dt.Lambda(lambda: lambda image: normalize(image))\n",
    "normalized_training_image = load_training_image + normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "normalization_mask = dt.Lambda(lambda sigma: lambda image: image/255.0)\n",
    "\n",
    "training_mask_labels = dt.Combine([load_training_membranes, load_training_mitochondria])\n",
    "training_mask = training_mask_labels +  dt.Merge(lambda: lambda image: image[1]*1.0 - image[0])\n",
    "noise = dt.Gaussian(mu=0, sigma=lambda: np.random.rand() * 0.1)\n",
    "\n",
    "noised_mask = training_mask + normalization_mask + noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = dt.Combine([normalized_training_image, noised_mask])\n",
    "\n",
    "\n",
    "augmented_dataset = dt.FlipLR(combined)\n",
    "augmented_dataset += dt.Affine(\n",
    "    rotate=lambda: np.random.rand() * 360,\n",
    "    shear=lambda: np.random.rand() * 20 - 10,\n",
    "    scale={\n",
    "        \"x\": np.random.rand() * 0.3 + 0.85,\n",
    "        \"y\": np.random.rand() * 0.3 + 0.85\n",
    "    },\n",
    "    mode=\"reflect\"\n",
    ")\n",
    "\n",
    "dataset = dt.ConditionalSetFeature(\n",
    "    on_true=combined,\n",
    "    on_false=augmented_dataset,\n",
    "    condition=\"is_validation\",\n",
    "    is_validation=lambda validation: validation \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels from storage\n",
    "def get_image(image):\n",
    "    return image[0]\n",
    "\n",
    "def get_mask(image):\n",
    "    return image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as utils\n",
    "\n",
    "\n",
    "NUMBER_OF_IMAGES = 8\n",
    "for image_index in range(NUMBER_OF_IMAGES):\n",
    "    image_tuple = dataset.update(sigma=0).resolve()\n",
    "#     print(image.get_property(\"index\", get_one=False))\n",
    "    image = get_image(image_tuple)\n",
    "    mask = get_mask(image_tuple)\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from deeptrack.models import KerasModel\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_init = RandomNormal(mean = 0.0, stddev = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(conv_layer_dimension,\n",
    "                      kernel_size = (3,3),\n",
    "                      strides = 1,\n",
    "                      weight_init = weight_init,\n",
    "                      **kwargs):\n",
    "    def call(x):\n",
    "        y = layers.Conv2D(conv_layer_dimension,\n",
    "                   kernel_size = kernel_size,\n",
    "                   strides = strides,\n",
    "                   padding = \"same\",\n",
    "                   kernel_initializer = weight_init)(x)\n",
    "        y = InstanceNormalization()(y)\n",
    "        y = layers.LeakyReLU(0.2)(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    return call \n",
    "\n",
    "def residual_block(conv_layer_dimension,\n",
    "                   kernel_size = (3,3),\n",
    "                   strides = 1,\n",
    "                   weight_init = weight_init,\n",
    "                   **kwargs):   \n",
    "    def call(x): \n",
    "        identity =  layers.Conv2D(conv_layer_dimension,\n",
    "                           kernel_size = (1,1))(x)\n",
    "        \n",
    "        y = layers.Conv2D(conv_layer_dimension,\n",
    "                   kernel_size = kernel_size,\n",
    "                   strides = strides,\n",
    "                   padding = \"same\",\n",
    "                   kernel_initializer = weight_init)(x)\n",
    "        y = InstanceNormalization()(y)\n",
    "        y = layers.LeakyReLU(0.2)(y)\n",
    "        \n",
    "        y = layers.Conv2D(conv_layer_dimension, \n",
    "                   kernel_size = kernel_size,\n",
    "                   strides = 1, \n",
    "                   padding = 'same',\n",
    "                   kernel_initializer = weight_init)(y)\n",
    "        y = InstanceNormalization()(y)\n",
    "        \n",
    "        y = layers.Add()([identity, y])\n",
    "        \n",
    "        return layers.LeakyReLU(0.2)(y) \n",
    "    \n",
    "    return call \n",
    "\n",
    "def pooling_block(conv_layer_dimension,\n",
    "                  kernel_size = (3,3),\n",
    "                  strides = 2,\n",
    "                  weight_init = weight_init,\n",
    "                  **kwargs):\n",
    "    def call(x):\n",
    "        y = layers.Conv2D(conv_layer_dimension,\n",
    "                   kernel_size = kernel_size,\n",
    "                   strides = strides,\n",
    "                   padding = \"same\",\n",
    "                   kernel_initializer = weight_init)(x)\n",
    "        y = InstanceNormalization()(y)\n",
    "        y = layers.LeakyReLU(0.2)(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    return call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolution_block(conv_layer_dimension = None,\n",
    "                          kernel_size = (3,3),\n",
    "                          strides = 1,\n",
    "                          weight_init = weight_init,\n",
    "                          **kwargs):\n",
    "    def call(x):\n",
    "        y = layers.UpSampling2D(interpolation = 'bilinear')(x)\n",
    "        y = layers.Conv2D(conv_layer_dimension,\n",
    "                   kernel_size = kernel_size,\n",
    "                   strides = strides,\n",
    "                   padding = \"same\",\n",
    "                   kernel_initializer = weight_init)(y)\n",
    "        y = InstanceNormalization()(y)\n",
    "        y = layers.LeakyReLU(0.2)(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    return call    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.models import unet\n",
    "    \n",
    "    \n",
    "generator = unet(\n",
    "    input_shape = (None, None, 1),                            # shape of the input\n",
    "    conv_layers_dimensions = (16, 32, 64, 128, 256, 512), # number of features in each convolutional layer\n",
    "    base_conv_layers_dimensions = (1024,),                  # number of features at the base of the unet\n",
    "    output_conv_layers_dimensions = (16, 16),               # number of features in convolutional layer after the U-net\n",
    "    steps_per_pooling = 2, #2                                 # number of convolutional layers per pooling layer\n",
    "    number_of_outputs = 1,                                  # number of output features\n",
    "    output_activation = \"tanh\",                             # activation function on final layer\n",
    "    compile = False,\n",
    "    output_kernel_size = 1,\n",
    "    layer_functions = {\n",
    "            \"encoder_convolution_block\"    : convolution_block,\n",
    "            \"bottleneck_convolution_block\" : residual_block,\n",
    "            \"decoder_convolution_block\"    : convolution_block,\n",
    "            \"pooling_function\"             : pooling_block,\n",
    "            \"upsampling_function\"          : deconvolution_block\n",
    "            }\n",
    ")\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block_discriminator(conv_layer_dimension,\n",
    "                      kernel_size = (4,4),\n",
    "                      strides = 2,\n",
    "                      weight_init = weight_init,\n",
    "                      avoid_conv_layer = 16,\n",
    "                      **kwargs):\n",
    "    def call(x):\n",
    "        y = layers.Conv2D(conv_layer_dimension,\n",
    "                   kernel_size = kernel_size,\n",
    "                   strides = strides,\n",
    "                   padding = \"same\",\n",
    "                   kernel_initializer = weight_init)(x)\n",
    "        \n",
    "        if conv_layer_dimension is not avoid_conv_layer: \n",
    "            y = InstanceNormalization(axis = -1, center = False, scale = False)(y)\n",
    "            \n",
    "        y = layers.LeakyReLU(0.2)(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(*args):\n",
    "    def call(x):\n",
    "        return x\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.models import convolutional\n",
    "\n",
    "discriminator = convolutional(\n",
    "    input_shape = (256, 256, 1),                       # shape of the input\n",
    "    aux_input_shape = (256, 256, 1),  \n",
    "    conv_layers_dimensions = (16, 32, 64, 128, 256),   # number of features in each convolutional layer\n",
    "    dense_layers_dimensions = (),                      # number of neurons in each dense layer\n",
    "    number_of_outputs = 1,                             # number of neurons in the final dense step (numebr of output values)\n",
    "    compile = False,\n",
    "    output_kernel_size = 4,\n",
    "    layer_functions_ = {\n",
    "            \"convolution_block\" : convolution_block_discriminator,\n",
    "            \"pooling_function\"  : identity,\n",
    "            }\n",
    ")\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam                                 \n",
    "\n",
    "# model\n",
    "model = dt.models.cgan(generator = generator, \n",
    "             discriminator = discriminator,\n",
    "             discriminator_loss = \"mse\",\n",
    "             discriminator_optimizer = Adam(lr = 0.0002, beta_1 = 0.5),\n",
    "             discriminator_metrics = \"accuracy\",\n",
    "             assemble_loss = [\"mse\",\"mae\"],\n",
    "             assemble_optimizer = Adam(lr = 0.0002, beta_1 = 0.5),\n",
    "             assemble_loss_weights = [1, 0.5],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.generators import Generator, ContinuousGenerator\n",
    "\n",
    "data_generator = ContinuousGenerator(\n",
    "    dataset,\n",
    "    label_function=get_image,\n",
    "    batch_function=get_mask,\n",
    "    batch_size = 16,\n",
    "    min_data_size=256,\n",
    "    max_data_size=257,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with data_generator:\n",
    "    for epoch in range(12,200):\n",
    "        model.fit(\n",
    "            data_generator, \n",
    "            epochs = 50, \n",
    "            steps_per_epoch=8\n",
    "        )\n",
    "        model.save_weights(\"noised_model\" + str(epoch) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model\" + str(0) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "datas = [dataset.update(validation=True).resolve() for _ in range(7)]\n",
    "            \n",
    "for ep in range(15, 20):\n",
    "    model.load_weights(\"model\" + str(ep) + \".h5\")\n",
    "    print(ep)\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(3, 7, figsize = (80, 35))\n",
    "    \n",
    "    data = get_mask(data_tuple)\n",
    "    label = get_image(data_tuple)\n",
    "\n",
    "    for i, data_tuple in enumerate(datas):\n",
    "        \n",
    "\n",
    "        prediction = model.predict(np.array([data]))\n",
    "        axs[0,i].imshow(data, vmin = -1, vmax = 1)\n",
    "        axs[0,i].axis(\"off\")\n",
    "\n",
    "        axs[1,i].imshow(label)\n",
    "        axs[1,i].axis(\"off\")\n",
    "\n",
    "        axs[2,i].imshow(prediction[0, ..., 0], vmin=-1, vmax=1)\n",
    "        axs[2,i].axis(\"off\")          \n",
    "\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "\n",
    "for ep in range(12, 25):   \n",
    "    # ep = 19\n",
    "    model.load_weights(\"noised_model\" + str(ep) + \".h5\")\n",
    "    print(ep)\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(3, 7, figsize = (80, 35))\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(7):\n",
    "\n",
    "        data_tuple = dataset.update(validation=True, index=55, sigma=0.02*i).resolve()\n",
    "        data = get_mask(data_tuple)\n",
    "        label = get_image(data_tuple)\n",
    "\n",
    "\n",
    "        prediction = model.predict(np.array([data]))\n",
    "\n",
    "        axs[0,i].imshow(data, vmin = -1, vmax = 1)\n",
    "        axs[0,i].axis(\"off\")\n",
    "\n",
    "        axs[1,i].imshow(label)\n",
    "        axs[1,i].axis(\"off\")\n",
    "\n",
    "        axs[2,i].imshow(prediction[0, ..., 0], vmin=-1, vmax=1)\n",
    "        axs[2,i].axis(\"off\")          \n",
    "\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloss = []\n",
    "gloss = []\n",
    "\n",
    "with open(\"loss.txt\", 'r') as f:\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        a = f.readline()\n",
    "        if len(a) > 5:\n",
    "            idx = a.find(\"D loss:\")\n",
    "            dloss.append(float(a[idx+8:idx+14]))\n",
    "            idx = a.find(\"G loss:\")\n",
    "            gloss.append(float(a[idx+8:idx+14]))\n",
    "        \n",
    "        if len(dloss) >= 1000:\n",
    "            break\n",
    "            \n",
    "            \n",
    "scipy.io.savemat(\"../../figures/gan_loss.mat\", {\n",
    "    \"dloss\": dloss,\n",
    "    \"gloss\": gloss\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"noised_model11.h5\")\n",
    "validation_set = [dataset.update(validation=True, sigma=0.05).resolve() for _ in range(number_of_validation_files)]\n",
    "validation_data = [get_mask(X) for X in validation_set]\n",
    "validation_labels = [get_image(X) for X in validation_set]\n",
    "\n",
    "\n",
    "predictions = model.predict(np.array(validation_data))\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "scipy.io.savemat(\"../../figures/MitoGAN.mat\", {\n",
    "    \"data\": validation_data,\n",
    "    \"labels\": validation_labels,\n",
    "    \"predictions\": predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = [d[0] for d in data_generator.data]\n",
    "lab = [d[1] for d in data_generator.data]\n",
    "scipy.io.savemat(\"../../figures/MitoGAN_raw.mat\", {\n",
    "    \"masks\": dat,\n",
    "    \"images\": lab,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.update(validation=True, sigma=0.01)\n",
    "\n",
    "noise.update(sigma=0.01)\n",
    "noise.sigma.current_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
